Group 1
1.  docker build -t <image_name> <path_to_locate_dockerfile>
    docker build -t python_image ./
    docker build -t python_image -f Dockerfile.nodejs.prod ./

2.  docker build -t <image_name>:<tag> <path_to_locate_dockerfile>
    docker build -t python_image:v1.0 ./
    docker build -t python_image:v1.0 -f Dockerfile.python.prod ./

2.1 Say you have a docker file name Dockerfile.node.dev, how do you build an image from this
    Dockerfile?
    -
    docker build -f Dockerfile.node.dev -t node_image:v1 ./

3.  docker images
    docker image ls

4.  - go to hub.docker.com
    - search for node, select the first verified node result that comes up with 1B+ downloads
    - click on tags tab
    - in the [filter tag input], search for "alpine" and select any image you want

5.  docker image rm <image_name>
    docker rmi <image_name>

6.  docker image rm image_1 image_2 image_3 {...}

7.  docker image rm -f $(docker image ls -q)
    docker rmi -f $(docker images -q)
    --
    docker image prune -f {Remove all dangling images (-f = by force (without confirmation))}
    docker image prune -a {Remove all unused images (with confirmation):}
        Unused images are those that are not currently associated with any containers, including those that are
        tagged.
        Note: Unlike the previous command, this will delete both dangling images and images that are not currently
        in use but might still have tags.
    docker image prune -a -f {Remove all unused & dangling images (without confirmation):}

8.  - what can you say about using the COPY command
      The COPY command is used to copy files & directories from the host machine into the Docker image
      e.g: COPY <file> <working-directory-in-the-image>

    - copy multiple files
      COPY package.json package-lock.json pnpm-lock.yml ./

    - using regex in package.json copy
      COPY package*.json ./ {
            COPY *.txt *(.js|.ts) picture* ./
            The COPY instruction in Docker does not support advanced pattern matching
            or glob patterns like *, ?, or complex regex patterns directly.
        }

    - copy files with white space in their names
      COPY ["file with space.txt", "."]

    - copying everything
      COPY . ./

    - difference btw COPY and ADD
      ADD and COPY commands both carry out the same task, but the ADD command can do a little bit more {
        1. ADD can copy from a url e.g ADD https://github.com/stanley/come.txt ./
        2. ADD can copy from a zipped file into your working directory e.g ADD code.tar ./
           it will unzip the file and copy the contents
    }

9. RUN addgroup -S app && adduser -S -G app app {
    you must put -S before -G, it is the correct way of doing it, you're saying create a -S system user called
    "app" and add the user to a group -G called "app"
}

10. USER app

11. COPY --chown=app:app . ./
    RUN chown -R app:app /usr/src/app
    {
        Use COPY --chown=app:app . ./ when you are copying files and want to set their ownership in one step.
        Use RUN chown -R app:app /usr/src/app when you need to change the ownership of files or directories
        that are already present in the image from previous layers or build steps.

        chown = stands for "change owner"
        -R = This flag stands for "recursive"
        app:app = This specifies the new owner and group for the files.
                The first app refers to the username, and the second app refers to the group name.
        /usr/src/app = The command will change the ownership of all files and subdirectories within this path

        chatGPT say better to do: "COPY --chown=app:app . ./" than: "RUN chown -R app:app ./"
    }


Group 2.
1.  - tell us about the CMD command and how do you use it
      CMD is used to execute a command provided whenever the image is used to start up a container
      e.g:
        CMD npm run dev (runs the command: "npm run dev". but it starts a new shell session to run this command)
        or
        CMD ["npm", "run", "dev"] (this is better as it does not spin up any new shell session. so it is faster)

    - what are the alternatives to CMD command, explain the diff btw CMD and it's alternatives
      An alternative to CMD is ENTRYPOINT, e.g ENTRYPOINT ["npm", "run", "dev"].
      the difference is that the CMD command can be over-ridden when starting the container, while
      that of ENTRYPOINT cannot be over-ridden

2.  Go to hub.docker.com. create a new repo (the repo name is going to be the same name you'll
    use for the image), now come back to your vsCode terminal and do:
    docker login
    docker image tag <image_name>:tag <username>/<myRepo>:<tag>
      or docker image tag <img_id> <username>/<myRepo>:<tag>
    docker push <username>/<myRepo>:<tag>
    https://hub.docker.com/r/username/myapp - to verify that the image has been pushed
    -
    e.g
    docker image tag react_app:latest stanleychukwu17/kit_react_app:v1.1.0
    docker push stanleychukwu17/kit_react_app:v1.1.0

2.1 what is the shortcut for "docker image tag"
    - docker tag
      e.g:  docker image tag go-app my-registry/go-app:v1
      or:   docker tag go-app my-registry/go-app:v1

3.  docker run -d --name react_container -p 3000:3000 react_image:latest

4.  a. docker run -it \
        --name postgres \
        -v ${PWD}/pg_data:/var/lib/postgresql/data \
        -e POSTGRES_PASSWORD=password \
        -p 5432:5432 \
        postgres:latest

    b. docker container ls (-a)
        docker ps (-a)

5.  0. docker logs CONTAINER_ID_or_NAME = show all logs
    a. docker logs -f CONTAINER_ID_or_NAME
    b. docker logs --tail 100 my_container {shows last 100 logs}
    c. docker logs -f -t my_container (or) docker logs -ft my_container

6.  1. docker exec -it my_container ls
    2. docker exec -it my_container mkdir /path/to/new_directory
    3. docker exec -it my_container sh or docker exec -it my_container (/bin/sh | /bin/bash)

7.  1. docker exec -it my_container sh (or) docker exec -it my_container bash
        - for alpine images, they're too small so they do not carry the more recent bash terminal,
          you can only use shell terminal's
        - for ubuntu based images, you can use bash because these ubuntu based images are larger and
          carry the bash terminal

    2.  docker exec -it -u root my_container sh {or}
        docker exec -it -u root CONTAINER_ID_or_NAME /bin/sh {where -u == --user}

8. docker attach CONTAINER_ID_or_NAME
    note this attaches to the main process as its own user, not as root unless the main process is running as root.
    For attaching to a running shell as root:
    docker exec -it -u root CONTAINER_ID_or_NAME /bin/bash
    (or)
    docker exec -it -u root CONTAINER_ID_or_NAME

9.  - remove a docker container - use the 2 methods available
        docker rm -f CONTAINER_ID_or_NAME
        docker container rm -f CONTAINER_ID_or_NAME

    - remove all containers
        docker rm -f $(docker ps -aq)

    - how do you start and stop an already existing container
        docker start <CONTAINER_ID_or_NAME>
        docker stop <CONTAINER_ID_or_NAME>

10. docker volumes
    0. volumes are a way to persist data generated by Docker containers. They are separate from the container's
      filesystem and exist outside the container's lifecycle, making them ideal for storing persistent or shared data.
      -
      - docker volume create <my_volume>
      - docker volume ls
      - docker volume inspect <my_volume>
      - docker volume rm -f <my_volume>

    1. {
        bind mount: this volume is not managed by docker, it binds a directory from the host machine into
        a docker container
        e.g docker run -d --name my_container -v /host/path:/path <my_image>
        -
        named volume: is managed by docker, it stores the volume in an area managed by docker, it is
        usually faster and better than bind mount.
        e.g docker run -d --name <my_container> -v <name_of_volume>:/path <my_image>
    }

    2. {
        docker run -d \
            --name postgres_container \
            -p 5432:5432 \
            -v ${PWD}/pg_data:/var/lib/postgresql/data \ {bind_mound} or
            -v pg_data:/var/lib/postgresql/data \ {name_volume}
            -e POSTGRES_PASSWORD=password \
            postgres:latest
    }
    3. {
        docker run -it
          --name my_node_app
          -v ${PWD}:/usr/src/app    or    -v .:/usr/src/app
          -v ${PWD}:/usr/src/app:ro     {where ro is read only}
          -w /usr/src/app
          node:20.16.0 bash

        explanation:
          -w /usr/src/app: This sets the working directory inside the container to /usr/src/app. When you run bash
            (or any other command), it will execute from this directory. If you don't specify -w,
            the working directory will be the container's default (typically / or a specific directory
            depending on the image)

        to prevent docker from bind mounting the "node_modules" folder, we do:
        docker run -it \
            --name my_node_app \
            -v ${PWD}:/usr/src/app \
            -v /usr/src/app/node_modules \
            -w /usr/src/app \
            node:20.16.0 bash

        -v /usr/src/app/node_modules: Mounts an anonymous volume on-top of /usr/src/app/node_modules, effectively
            hiding the node_modules directory from your host. This setup ensures that the container uses its own
            node_modules directory, preventing any changes from affecting your local node_modules.
            With this, Docker creates an anonymous volume for node_modules, and once the container
            is removed, Docker cleans up the volume automatically.
    }


Group 3
1.  docker cp <container_id>:/path/to/file/in/container /path/on/your/local/system
    e.g docker cp container_id:/usr/src/app/file.txt /home/user/local-folder/
    ---
    docker cp /path/on/your/local/system <container_id>:/path/in/container
    e.g docker cp /home/user/local-folder/file.txt <container_id>:/usr/src/app/

2.  docker system prune -f
    docker container prune -f
    docker volume prune
    docker network prune -f
    docker image prune -f
    ---
    docker rm -f $(docker ps -aq) # for containers
    docker volume rm -f $(docker volume ls) # for volumes
    docker network rm -f $(docker network ls) # for networks
    docker rmi -f $(docker image ls -q) # for images

3. create a Dockerfile for react, golang, node.js {
    dev - see ./d-file/dev/
    prod - see ./d-file/prod/
}

4.see: ./compose/docker-compose.yml

5. build images from the compose file created
    - don't use --no-cache
      docker-compose build

    - use --no-cache
      docker-compose build --no-cache

    - see the list of images created
      docker-compose images
      docker images
      docker image ls

6. using the compose file 
    - start the containers
      docker-compose up
      docker-compose up --build     # to rebuild the images before using the images to start the container
      docker-compose up -d          # to run in detached mode

    - see the list of containers from this compose file
      docker-compose ps
      docker-compose ps -a (or --all) # will show all containers, both running and stopped
      docker-compose ps -q (or --quiet) # will show only container ids

    - stop & remove the running containers for only this compose file
      docker-compose down

    - Stop running containers without removing them
      docker-compose stop

    - Start previously stopped containers without rebuilding or recreating them
      docker-compose start
      
    - use a different docker-compose file to start some container (e.g: docker-compose.dev.yml)
      docker-compose -f ./docker-compose.dev.yml up

    - Restart the containers defined in the docker-compose.yml file
      docker-compose restart
    
    - Remove stopped service containers
      docker-compose rm
      docker-compose rm <service-name>

    - Pause the running containers (will stop all processes without removing them)
      docker-compose pause

    - Unpause previously paused containers
      docker-compose unpause

7. Read: so more docker-compose commands
    - View logs for the services defined in docker-compose.yml:
      docker-compose logs
      docker-compose logs -f
      docker-compose logs <service-name>  # For specific service logs

    - Execute a command inside a running container (similar to docker exec)
      docker-compose exec <service-name> <command>
      e.g: docker-compose exec frontend sh

    - Run a one-time command against a service. This starts a container and runs the
      specified command, then stops the container afterward.
      -
      docker-compose run <service-name> <command>
      e.g: docker-compose run frontend npm install

    - Run a service once and remove the container after it finishes.
      docker-compose run --rm <service-name> <command>

    - Pull the latest image for all services defined in the docker-compose.yml file.
      docker-compose pull

    - Push built images to a Docker registry.
      docker-compose push

    - Validate and view the composed configuration in YAML format. It’s useful to check for any syntax errors in the docker-compose.yml file.
      docker-compose config

    - Display the current version of Docker Compose
      docker-compose version

    - Display the running processes in the containers (similar to docker top).
      docker-compose top

8.  see: D:\Sz - projects\0-templates\2-docker-templates\0-docker-compose
    you can open it in vsCode

9.  Read: docker-compose | restart vs deploy.restart-policy
    The restart option and the deploy.restart-policy option in Docker Compose are both used to manage the
    container's restart behavior, but they have different scopes and usage contexts:

    1. restart (Docker Compose - Local mode)
        - This option is used when you're running Docker Compose locally in a non-Swarm environment
          (i.e., standard docker-compose up).
        - It controls the restart policy for individual containers on the local machine. The container is
          restarted based on the specified policy (e.g., always, on-failure, no, unless-stopped).
        e.g:
            services:
                app:
                    image: my-app
                    restart: always


    2. deploy.restart-policy (Docker Compose - Swarm mode)
        - This option is only applicable when using Docker Swarm, which is a clustering and orchestration tool.
          Swarm is used for managing multiple Docker containers across a cluster of machines.
        - It defines the restart policy for services running in a Swarm environment.
        - The restart policy governs how Docker Swarm should handle container failures or restarts in a
          cluster environment. Swarm ensures that the desired number of replicas are always running so if one
          container fails, it will automatically be restarted or replaced to meet the defined service replica count.
        - The deploy.restart-policy applies only in Swarm mode and works in conjunction with other Swarm features
          like service scaling.
        e.g:
            version: "3.8"
            services:
                app:
                    image: my-app
                    deploy:
                        restart-policy:
                            condition: on-failure
                            max-attempts: 3
