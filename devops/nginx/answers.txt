1.  Nginx
    - what is Nginx
      - Nginx is a useful tool that can be used as a web server that serves static/dynamic content or
        can be used as reverse proxy which helps to load balance request among your upstream/backend servers.
      - It can also help with Backend re-routing, caching of files, url-rewriting e.t.c 
      - Nginx can inspect a request(both the headers and the body content), it can modify the headers,
        add more cookies e.t.c Nginx is a powerful tool

    - talk about what a normal architecture look like vs what an Nginx architecture would look like
      - normal architecture:
        [users request] -> [server] -> [database]
    
      - Nginx architecture
        [users request] -> [nginx]  -> [server] ->
                                    -> [server] -> [database]
                                    -> [server] ->
      
      with the normal architecture, the request are going straight to the severs and it is not the best,
      because if the request becomes too much for the server it will crash it, it is also difficult
      to scale with the normal architecture, because every time you add a new server in the backend,
      you need to start changing frontend code -> as this can become pretty complex. but with the
      Nginx architecture, everything becomes easy to manage, if you need to scale your backend servers,
      you'll only need to update your nginx config with the new backend ports

    - what are the following concepts/terms in Nginx? {Frontend, Backend, Upstream, Downstream}
        Frontend: refers to all communication between the user_request & Nginx

        Backend: refers to all communication between Nginx & the servers

        Upstream: refers to the servers or services that NGINX communicates with to fulfill a request
            When NGINX acts as a reverse proxy or load balancer, it forwards client requests to upstream
            servers (like application servers or backend services).
            The upstream servers handle the actual processing of the request and then return the result to
            NGINX, which then sends the response back to the client.

        Downstream: refers to the end-users or the clients that send requests to your NGINX server.
            When a client sends an HTTP request to NGINX, NGINX sends it to the upstream and then the
            upstream processes it and responds to Nginx, Nginx in-turns transports the response back to
            the user, the process of this information coming from the "upstream servers" to the
            "user" is known as "downstream" in Nginx

    - Tell us about the 7 layers in OSI Model
        Please - Physical layer 1
        Do - Data-link layer 2
        Not - Network layer 3
        Throw - transport (TCP/IP) layer 4
        Sausage - session layer 5
        Pizza - presentation layer 6
        Away - application layer 7
        ---
        upper layer = [application layer, presentation layer, session layer]
        lower layer = [transport layer, session layer, presentation layer, application layer]

2. Talk about Layer 4 and Layer 7 proxying in Nginx
    Layer 4 (Transport Layer of the OSI model (TCP/UDP)):
      - Layer 4 proxying operates at the Transport Layer of the OSI model (TCP/UDP)
      - NGINX forwards raw TCP/UDP packets without inspecting the content
      - Used for protocols like MySQL, FTP, or custom services
      - Provides basic load balancing and traffic distribution based on IP and port

        e.g:
        stream {
            upstream backend {
                server backend1.example.com:3306;
                server backend2.example.com:3306;
            }

            server {
                listen 3306;
                proxy_pass backend;
            }
        }

    Layer 7 (Application Layer, HTTP proxying):
     - Layer 7 proxying works at the Application Layer and understands HTTP/HTTPS content
     - NGINX can inspect headers, cookies, and URLs to make routing decisions
     - Allows for more advanced features like URL rewriting, caching, and SSL termination

        e.g:
        http {
            upstream backend {
                server backend1.example.com;
                server backend2.example.com;
            }

            server {
                listen 80;

                location / {
                    proxy_pass http://backend/;
                }
            }
        }
    
    You see that layer 7 in written inside the "http" block and layer 4 proxying is written
    in the "stream" block

3. Talk about TLS termination and TLS passthrough in Nginx
    1. TLS Termination:
        - TLS Termination refers to NGINX decrypting the incoming SSL/TLS traffic (i.e: HTTPS) and
          then forwarding the unencrypted traffic (HTTP) to the backend servers
        - NGINX handles the decryption process, offloading this task from the backend servers,
          making it more efficient
        - TLS Termination operates at Layer 7 because NGINX decrypts and inspects the traffic (HTTP)

        e.g:
        server {
            listen 443 ssl;
            server_name example.com;

            ssl_certificate /etc/nginx/ssl/cert.pem;
            ssl_certificate_key /etc/nginx/ssl/key.pem;

            location / {
                proxy_pass http://backend;  # Unencrypted HTTP forwarded to backend
            }
        }

    2. TLS Passthrough:
        - TLS Passthrough means that NGINX does not decrypt the incoming SSL/TLS traffic.
          Instead, it forwards the encrypted traffic directly to the backend server for decryption.
        - This is useful when you want to maintain end-to-end encryption between the client & the backend server
          (e.g: for security reasons or when the backend server needs to handle the SSL certificates).
        - NGINX acts as a transparent proxy in this case, forwarding encrypted traffic without inspecting
          or modifying it.
        - TLS Passthrough operates at Layer 4 because the encrypted traffic is passed through without
          decryption or inspection.

        e.g:
        stream {
            upstream backend {
                server backend1.example.com:443;  # Backend server with TLS (HTTPS)
                server backend2.example.com:443;  # Another backend for load balancing
            }

            server {
                listen 443;
                proxy_pass backend;  # Load balancing between backend1 and backend2
            }
        }

6. Read or explain the code in your nginx config
    http {}: inside the http block is where you configure everything about your nginx server
        when working with layer 7 proxying

    upstream {}: the upstream is used to group servers that nginx will be talking to at the "backend",
        you usually add a group name for each upstream you create, i.e upstream <group-name>.
        Nginx will distribute the request among the servers listed inside the upstream in a
        round-robin fashion by default.

    server {}: the server block is used to configure how Nginx will handle incoming request on
        the "frontend"
        - the listen 8080; tells Nginx to listen to request on port 8080
        - the location / {} & proxy_pass http://node_backend/; means all request to the root url /
            should be forwarded to the upstream "node_backend" group

    events {}: the event block is used to configure a-lot of settings, but here we use it to configure
        the maximum number of simultaneous connections that a worker process can handle.
        If your server receives more incoming connections than this limit allows, it might start to
        queue connections or reject them, depending on the load and configuration
        (such as keepalive_timeout or accept_mutex)

    worker_processes auto; this means nginx will automatically spawn worker processes based on the number
        of available CPU cores. each worker will be able to handle up to 1024 simultaneous connections
        on each worker_processes and depending on how many worker_connections you set for each worker_processes
        to handle

7. Read about exposing ports of your docker container
    when working with docker and nginx, the only ports that should be exposed should be only the nginx port,
    all other containers port should not be exposed, they should be internal

8. see answers in:
    ./section1/11-nginx-conf/nginx.conf

9. Understanding nginx timeouts for efficient configuration
    - Read: see list of frontend & backend timeouts
        - Frontend timeouts:
            client_header_timeout
            client_body_timeout
            send_timeout
            keepalive_timeout
            lingering_timeout
            resolver_timeout
        - Backend timeouts:
            proxy_connect_timeout
            proxy_send_timeout
            proxy_read_timeout
            keepalive_timeout
            proxy_next_upstream_timeout

    - Read: see explanation of frontend timeouts
      - client_header_timeout
        defines a timeout for reading client request header, if a client does not transmit the entire header
        within this time, the request is terminated with 408(Request timeout) error.
        default: 60s

      - client_body_timeout
        defines a timeout for reading client request body. the timeout is set only for a period between two
        successive read operations, not for the transmission of the whole request body.
        If a client does not send anything within this period, the request is terminated with a
        408(Request timeout) error
        default: 60s

      - send_timeout
        sets a timeout for transmitting a response to the client. the timeout is set only between two
        successive write operations, not for the transmission of the whole response. if the client does
        not receive anything within this time, the connection is closed
        default: 60s

      - keepalive_timeout
        sets a timeout for which the connection with nginx server should stay connected to the client
        without any communications, if this timeout is reach, the client is disconnected
        default: 75s

      - lingering_timeout
        specifies the maximum waiting time for more client data to arrive, if data are not received during
        this time, the connection is closed

      - resolver_timeout
       sets a timeout for dns name resolution
       default: 30s

    - Read: see explanation of backend timeouts
      - proxy_connect_timeout
        defines a timeout for establishing a connection with a proxied server.
        default 75s

      - proxy_send_timeout
        sets a timeout for transmitting of request to the proxied server. the timeout is set only between
        two successive write operations, not for the transmission of the whole request. if the proxied server
        does not receive anything within this time, the connection is closed

      - proxy_read_timeout
        defines a timeout for reading a response from the proxied server. the timeout is set only between two
        successive read operations, not for the transmission of the whole response. if the proxied server does
        not transmit anything within this time, the connection is closed

      - keepalive_timeout
        sets a timeout during which an idle keepalive connection to an upstream server will stay open

      - proxy_next_upstream_timeout
        Limits the time during which a request can be passed to the next server.
        the 0 value turns off this limitation, the default is 0
        read more {
            say you have 3 servers connected to nginx and nginx sends a request to server1 and server1 fails,
            nginx will try server2, if 2 fails, it will try server3. if 3 fails, it will go back to server1
            and try again, so this timeout can help to kil this loop otherwise nginx will continue to loop
            all through the 3 servers until 60s is reached
        }

10. Nginx as a layer 7 proxy, look at the example, explain what is going on and re-write it
      http {
        upstream all_apps {
            server app1_backend:2222;
            server app1_backend:3333;
            server app2_backend:3333;
            server app2_backend:4444;
        }

        upstream app1 {
            server app1_backend:2222;
            server app1_backend:3333;
        }

        upstream app2 {
            server app2_backend:3333;
            server app2_backend:4444;
        }

        server {
            listen 80;

            server_name localhost;

            location / {
                proxy_pass http://all_apps/;
            }

            location /app1 {
                proxy_pass http://app1/;
            }

            location /app2 {
                proxy_pass http://app2/;
            }

            location /admin {
                return 403;
                # or you can do: return 403 "You are forbidden from visiting this page";
            }
        }

        server {
            listen 79453;

            server_name localhost;

            location /admin {
                proxy_pass http://all_apps/;
            }
        }
      }

    - explanation
        in the example above, we have 3 upstream servers, when a user visits the root url (i.e localhost:80),
        nginx takes them to the upstream server "all_apps", if they visit localhost/app1, they are taken to
        "app1_backend", if they visit localhost/app2, they are taken to "app2_backend".
        but no one is allowed to visit /admin on port 80, i.e (localhost/admin), but if they go to port 79453
        (localhost:79453/admin), they'll be proxied to the right upstream

11. Nginx as a layer 4 proxy, look at the example, explain it and re-write it
    - code
      stream {
        upstream all_apps {
            server app1_backend:2222;
            server app1_backend:3333;
            server app2_backend:4444;
            server app2_backend:5555;
        }

        server {
            listen 80;
            proxy_pass http://all_apps/;
        }
      }

    - explanation
      with layer 4 proxying, you can't really do much, you're just passing the request to one of the servers

12. Enable HTTPS on Nginx
    - Read: how do you enable https on your nginx server
      if you want to enable https on nginx, you need a working dns name, now you follow the steps below

      1. obtain an SSL certificate
        - let us use certbot (will only work in a linux environment, will not work in your git bash environment)

        - sudo apt-get update
          sudo apt-get install -y certbot python3-certbot-nginx
          sudo certbot --nginx
        
        - certbot will automatically configure nginx to use SSL

      2. configure listening to https in your server block
        server {
            listen 443 ssl;
            server_name stanleychukwu.com

            ssl_certificate /etc/ssl/certs/your_certificate.crt;  # Path to your SSL certificate
            ssl_certificate_key /etc/ssl/private/your_private.key;  # Path to your private key

            ssl_protocols TLSv1.2 TLSv1.3;  # Enforce strong protocols
            ssl_ciphers 'TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384';  # Secure ciphers

            # Other configuration options as needed...
            location / {
                root /var/www/your-site;
                index index.html index.htm;
            }
        }

        # test the configuration for syntax error and reload nginx
        sudo nginx -t
        sudo systemctl reload nginx
    
      3. Optionally: redirect http to https
        if you want to automatically redirect http traffic to https, add the following block before the https
        server block:

        server {
            listen 80;
            server_name stanleychukwu.com

            return 301 https://$host$request_uri; # redirects to https
        }

      4. Additional Tip
        You can also configure strict transport security to enforce HTTPS for browsers. the below can be
        added to your HTTPS server block:

        server {
            listen 443 ssl;

            add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;
        
        }
      
    - enable fast and secure TLS 1.3 on Nginx
        server {
            ...

            ssl_protocols TLSv1.3;
        }

    - enable http2 on Nginx
        server {
            listen 443 ssl http2;

            ssl_protocols TLSv1.3;
        }

13. if you have time, Read: the difference between HTTP/1 and HTTP/2
    see: ./section1/15-https/http2-http1.md


## Websockets with Nginx
15. - see what layer 4 proxying for nginx and websocket looks like
    - read some of the explanation



