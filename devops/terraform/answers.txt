1. The terraform core workflow is
    Write:
    Plan:
    Apply

2.  Terraform providers are plugins that allow Terraform to interact with various APIs and services. Each provider is 
    responsible for understanding the API of a specific service (like AWS, Azure, Google Cloud, or even custom APIs)
    and managing the lifecycle of the resources defined in your Terraform configuration.
    more_explanation {
        Providers enable you to:

        Define Resources: Specify what infrastructure components you want to create, such as virtual machines, databases,
            and networking resources.
        Manage State: Keep track of the state of your resources, allowing Terraform to understand the current 
            configuration and make necessary updates.
        Provision Infrastructure: Automate the creation, modification, and deletion of resources as defined in your
            configuration files.
    }

3.
    terraform {
        required_providers {
            aws = {
                source = "hashicorp/aws"
                version = "~>5.0"
            }
        }
    }

    provider "aws" {
        region = "eu-north-1"
        access_key = var.access_key
        secret_key = var.secret_key
    }

4.
    resource "aws_vpc" "main" {
        cidr_block = "10.0.0.0/16"
        enable_dns_support = true
        enable_dns_hostnames = true
    }

    resource = is a block.. i.e a "resource block"
    cidr_block, enable_dns_hostnames, enable_dns_support = arguments
    aws_vpc, main = label names
    aws_vpc = resource type.. i.e "aws_vpc resource type"
    main = local_name {used for local identification}

5. terraform init - this will download all of the required_providers

6. VPC -> Subnet -> Route table & Internet Gateway -> Security groups -> EC2 instance {
    For EC2 instance, we need:
        data for "ami" automatic fetching
        keyGen for ssh logging into your EC2 vm
        user_data = for initial vm set_up and installation of needed services to run the vm
}

7. resource "<provider>_<resource_type>" "<local_name>" {
    # arguments
}

8. Classless Inter Domain Routing
8.1 see ./answers/8.1_cidr_block.txt

9.
    resource "aws_vpc" "main" {
        cidr_block = "10.0.0.0/16"
        enable_dns_support = true
        enable_dns_hostnames = true

        tags = {
            Name = "Dev Env ${var.main_vpc_name}"
        }
    }

10. - terraform plan
    - terraform apply
    - terraform plan -out=tfplan or terraform plan -out tfplan
    - terraform apply "tfplan" or terraform apply "tfplan" -auto-approve

11. - terraform apply -auto-approve
    - terraform fmt
    - terraform fmt <name_of_folder>
      terraform fmt -diff
      terraform fmt -recursive
    - terraform validate

12. - terraform destroy
    - terraform destroy -auto-approve
    - terraform destroy -target "aws_vpc.main"
    - terraform apply -replace="aws_vpc.main"

13. D:\Sz - projects\0-exercise\terraform\answers\13_a.tf

14.
    - How do you declare a variable, what are the three & four arguments in a variable declaration
        with 3 arguments:
        variable "vpc_cidr_block" {
            default = "10.0.0.0/16"
            description = "The cidr block for the main vpc for development stage"
            type = string
        }
        with 4 arguments
        variable "av_zones" {
            description = "A list of availability_zones"
            type = list(string)
            default = ["...", "...", "..."]
            sensitive = true
        }
    - you save variables in two file: variables.tf & (terraform.tfvars or <any_name>.auto.tfvars)

15. terraform apply -auto-approve -var="vpc_cidr_block=10.0.0.0/16" -var="subnet_cidr_block=10.0.10.0/24"

16. terraform.tfvars does not compile with the other terraform files(i.e .tf files) into a single module
    - terraform.tfvars stores only the values. no description, no type
    - variables.tf stores everything, the (default, description & type)

17. touch production.tfvars
    terraform apply -auto-approve -var-file=production.tfvars
    or
    terraform apply -auto-approve -var-file="production.tfvars"

18. here is how to use it in your main.tf:
    resource "aws_vpc" "main" {
        cidr_block = var.vpc_cidr_block

        tags = {
            Name = "${var.environment_stage} VPC"
        }
    }

    - resource "aws_subnet" "web_subnet" {
        cidr_block = var.subnet_cidr_block
        vpc_id = aws_vpc.main.id
        availability_zone = var.subnet_availability_zone_1

        tags = {
            Name = "${var.environment_stage} subnet for VPC"
        }
    }

19. this is how they are applied into your config files
    -var & -var-file
    *.auto.tfvars
    terraform.tfvars & production.tfvars
    environment variables "TF_VAR_*"

20. A route table is a virtual router within your vpc, it controls routing for all subnets within the vpc
    An Internet Gateway: it allows communication between instances in a Virtual Private Cloud (VPC) and
        the internet

21. - An aws_security_group is an aws managed service that determines if internet traffic are permitted
        into or out of an instance
    - aws_security_group = You have to create this one by yourself using the resource "aws_security_group"
      aws_default_security_group = This one comes by default when you create the VPC, it is always better to leave
        this one alone and create new security groups (i.e aws_security_group)

22. 
    - add a variable to your variables.tf and terraform.tfvars file: "public_cidr"
        in variables.tf
        variable "public_cidr" {
            description = "everyone is allowed to visit this EC2 instance"
            type = list(string)
            default = ["0.0.0.0/0"]
        }
        in terraform.tfvars
        public_cidr = ["0.0.0.0/0"]

    - use the variable to create an aws_security_group
        resource "aws_security_group" "ec2_security" {
            vpc_id = aws_vpc.main.id
        
            ingress = [
                # for ssh connections
                {
                    from_port = 22
                    to_port = 22
                    protocol = "tcp"
                    cidr_blocks = var.public_cidr
                    description = "for ssh connections to the ec2"
                    ipv6_cidr_blocks = []
                    self             = false
                    security_groups  = null
                    prefix_list_ids  = null
                },
                # for http connection on port 80
                {
                    from_port = 80
                    to_port = 80
                    protocol = "tcp"
                    cidr_block = var.public_cidr
                    description = "for http connections to the ec2 on port 80"
                    ipv6_cidr_blocks = []
                    self             = false
                    security_groups  = null
                    prefix_list_ids  = null
                }
                # for http connection on port 8080
                {
                    from_port = 8080
                    to_port = 8080
                    protocol = "tcp"
                    cidr_block = var.public_cidr
                    description = "for http connections to the ec2 on port 8080"
                    ipv6_cidr_blocks = []
                    self             = false
                    security_groups  = null
                    prefix_list_ids  = null
                }
            ]

            # for all outgoing request
            egress = [{
                from_port = 0
                to_port = 0
                protocol = "-1" # any type of request
                cidr_block = ["0.0.0.0/0"]
                description = "rule for all outgoing request from the ec2, all traffic are allowed"
                ipv6_cidr_blocks = []
                self             = false
                security_groups  = null
                prefix_list_ids  = null
            }]
        
            tags = {
                Name = "EC2 security group"
            }
        }

    - Read: explanation of some of the options used in the ingress and egress
        1. ipv6_cidr_blocks = [] ?
          - What is ipv6_cidr_blocks:
            This field defines the list of allowed IPv6 CIDR blocks for the rule. IPv6 CIDR blocks specify which
            range of IPv6 addresses are allowed to access the resource.
          - Why is it empty ([]) ?
            The ipv6_cidr_blocks is empty because the rule is likely intended for IPv4 connections only. Since no
            IPv6 addresses are specified, the field is left empty (or set to an empty list []). If you wanted to
            allow IPv6 access, you would provide a valid IPv6 CIDR block here, such as "2001:0db8::/32".

        2. self = false
          - What is self ?
            The self field specifies whether the rule applies to traffic originating from the same security group.
            When self = true, the rule allows traffic between instances that are associated with the same security group.
            This is useful for cases where you want to allow internal communication between instances in the same security group.
            The rule is set to false, meaning it does not allow traffic from instances within the same security group

        3. security_groups = null
          - What is security_groups?
            The security_groups field is used to specify which other security groups can send traffic to the instances
            associated with this rule. This allows you to restrict access to specific groups, as opposed to opening up
            access to all IPs or CIDR blocks
          - Why is it set to null?
            Setting security_groups = null means that this rule is not specifically restricting traffic based on other
            security groups. In other words, it does not restrict access to instances from other security groups.
            If you had specific security groups to allow, you would list them here

        4. prefix_list_ids = null
          - What is prefix_list_ids?
            The prefix_list_ids field allows you to specify AWS-managed prefix lists (collections of IP address ranges)
            to use in the rule. AWS offers managed prefix lists that include ranges for services like
            Amazon S3, CloudFront, and others. This allows you to define rules based on these predefined IP address ranges
            rather than manually specifying CIDR blocks
          - Why is it set to null?
            Setting prefix_list_ids = null means that the rule is not using any AWS-managed prefix lists. If this field were
            set with the ID of a prefix list (e.g., "pl-12345678"), it would allow traffic from the IP addresses included
            in that prefix list.

        5. Summary of All Fields:
          - ipv6_cidr_blocks = []: No IPv6 addresses are specified, implying the rule is for IPv4 traffic.
          - self = false: Traffic from instances within the same security group is not allowed.
          - security_groups = null: No specific security groups are specified, meaning the rule does not restrict
            based on other security groups
          - prefix_list_ids = null: No AWS-managed prefix lists are being used, meaning no predefined IP address
            ranges are referenced
          - {Each of these fields can be customized to control traffic flow based on different security needs}

23.
    resource "aws_instance" "my_vm" {
        ami =                           "ami-4094940048585fse2" or data.aws_ami.latest_amazon_linux2.ami
        instance_type =                 "t3.micro"
        subnet_id =                     aws_subnet.web_subnet.id
        vpc_security_group_ids =        [aws_security_group.ec2_security.id]
        associate_public_ip_address =   true
        key_name =                      aws_key_pair.test_ssh_key.key_name
        user_data =                     file("./entry_script.sh")
        count = 2

        tags = {
            Name = "My EC2 instance - Selling town EC2_1"
        }
    }

24. ssh-keygen -t rsa -b 2048 -C 'test key' -N '' -f ~/.ssh/test_rsa {
        -t rsa: Specifies the type of key to create, in this case, RSA.
        -b 2048: Sets the number of bits in the key, here 2048 bits.
        -C 'test key': Adds a comment to the key.
        -N '': used for encryption. Sets an empty passphrase for the key (not recommended for all use cases due to security reasons).
        -f ~/.ssh/test_rsa: Specifies the filename of the key file. and where to save the key
    }

25. chmod 400 ~/.ssh/test_rsa

26. 
    resource "aws_key_pair" "test_ssh_key" {
        key_name = "testing_ssh_key"
        public_key = file(<path_to_file>) (i.e C:/Users/STANLEY/.ssh/test_rsa.pub)
    }

    resource "aws_instance" "my_vm" {
        ...
        key_name = aws_key_pair.test_ssh_key.key_name
        ...
    }

27. ssh -i ~/.ssh/test_rsa ec2-user@<PublicIP>
27.1 sudo su - (i.e sudo switch user - where dash(-)=root)

28. 
    in variables.tf we do:
    variable "ssh_pubic_key_path" {
        description = "The path to where the ssh key is stored on my local computer"
        type = string
    }

    in terraform.tfvars we do:
    ssh_pubic_key_path = "C:/Users/STANLEY/.ssh/test_rsa.pub"

    in main.tf we do:
    resource "aws_key_pair" "test_ssh_key" {
        key_name = "testing_ssh_key"
        public_key = file(var.ssh_pubic_key_path)
    }

    Note: if you change the public_key value, a new instance is created, each instance belong to the key
        it was created with

29. Data sources are like a function, and their goal is to fetch data from cloud providers. An example is a
    list of ami images from an availability_zone
    -
    data "aws_ami" "latest_amazon_linux2" {
        owners = ["amazon"]
        most_recent = true   # if more than one image is returned, terraform will use the most recent image

        filter {
            name = "name"    # filter the result using the items in the value[] list below
            values = ["amzn2-ami-kernel-*-x86_64-gp2"]
        }

        filter {
            name = "architecture"
            values = ["x86_64"]
        }
    }
    {Now we need to update our aws_instance with the dynamic ami id}
    resource "aws_instance" "my_vm" {
        ami = data.aws_ami.latest_amazon_linux2.id
        ...
    }

30. outputs.tf (you can also do output.tf)

31. in your outputs.tf
    output "ec2_public_ip_address" {
        description = "The public IP address of the EC2 instance."
        value       = aws_instance.my_vm.public_ip
    }

    output "ec2_ami" {
        description = "The ami of our ec2 instance"
        value = aws_instance.my_vm.ami
    }

    output "vpc_id" {
        description = "ID of the main VPC"
        value = aws_vpc.main.id
    }

    output "ec2_instance_id" {
        description = "The ID of the EC2 instance."
        value       = aws_instance.my_vm.id
    }

32.
    - terraform output
    - terraform output ec2_public_ip_address
    - terraform output -json
    - 
      - terraform output -json > output.json
          Will not display output to the terminal, but will save output to output.json
      - terraform output -json | tee output.json
          Display the output in the terminal & Save the output into output.json
      - terraform output -json | tee output.json > /dev/null
          Will not display output to the terminal, but will save output to output.json

    - if you want to hide an output from display in the terminal, set sensitive = true, i.e {
        output "ec2_public_ip_address" {
            description = "The public IP address of the EC2 instance for ebay"
            value = aws_instance.my_vm.public_ip
            sensitive = true
        }
    }

33. Terraform state is a critical component of Terraform's infrastructure management process. It is a file
    that tracks the current state of your infrastructure as managed by Terraform. Terraform state acts
    as the source of truth for your managed infrastructure, enabling Terraform to track, update, and
    manage resources effectively.
    For more {
        1. **Purpose**: The state file maintains a mapping between your Terraform configuration and the
            actual resources deployed in your infrastructure. It helps Terraform understand what resources
            exist, their configurations, and how they relate to each other.

        2. **Storage**: By default, the state file is named `terraform.tfstate` and is stored locally in your
            working directory. However, in team environments or production settings, it’s common to use
            remote state storage solutions like Amazon S3, Azure Blob Storage, or Terraform Cloud for
            better management and collaboration.

        3. **Usage**: During operations like `terraform apply`, Terraform reads the state file to determine
            the changes that need to be made to your infrastructure. It then updates the state file with
            the latest information after applying the changes.

        4. **Locking and Security**: For remote state, locking mechanisms prevent simultaneous updates.
    }
    ---
    ---
    terraform state is stored in a terraform.tfstate file

34. - terraform show
    - terraform show | grep -A 20 aws_vpc -: means, show all resources, then pipe the result to the grep
        command and then search for aws_vpc, if you find the result, then show 20lines after it(i.e A20)
    - terraform show -target=<resource_address>
        e.g terraform show -target=aws_instance.my_vm
    - terraform show <plan_file> e.g terraform show tfplan

35. terraform state
    - terraform state list
    - terraform state show <resource_address>
        e.g terraform state show aws_instance.my_vm
    - terraform state pull
    - terraform state list | grep 'module.<module_name>'

36. running commands on you ec2 instance
    - which is the best for running commands on your ec2 instance (cloud-init or ansible)
        - For initial boot time configuration, i.e if you need to perform simple one time setup tasks when a VM is
            first launched, then use "cloud-init". it is the best tool. it is lightweight, easy to use and designed
            for exactly this Purpose
        - For ongoing configuration management, if you need to manage the configuration of servers throughout their
            lifecycle, including making changes, applying updates, or orchestrating complex tasks, Then use Ansible,
            it provides more power, flexibility and scalability
        # using both
            Many organization use both tools in tandem:
            ~ cloud-init for initial bootstrapping and configuration e.g installing docker, apache, httpd & ansible.
            ~ ansible for ongoing configuration management and complex orchestration after the initial setup is completed

    - create an entry-script.sh configuration that can be used in your ec2 instance
        ./answers/36.2-entry-script.sh

    - not_needed: Read: read about some of the highlights of using cloud-init
        ~ it is the standard for customizing cloud instances on spin up
        ~ it runs on most linux distributions and cloud providers
        ~ cloud-init can run per-instance or per-boot configurations

    - not_needed: create a cloud-init configuration in yaml called "web-app-template.yaml" and use it in your ec2
        - ./task/web-app-template-v1.yml - from teacher
        - ./task/web-app-template-v2.yml - from codeium

    - not_needed: explain the code in your cloud-init configuration
        -
        1. Adding groups to the system
        groups:
            - devops: [root, sys]
            - hashicorp
        The above is adding 2 groups to the system, it added the "devops" group with 2 users "root" & "sys",
        and also created another group "hashicorp" but without any users in this group

        -
        2. Adding users to the system. Users are added after groups are added
        users:
            - default               # this will be the default system user
            - name: terraform       # the name of the user
                gecos: terraform    # the GECOS field(General Electric Comprehensive Operating Supervisor)
                                        typically contains the full-name or the description of the user, but
                                        here, we used the same name as the username "terraform"
                shell: /bin/bash    # the default shell of the user
                primary_group: hashicorp        # adds a default group for the user
                sudo: ALL=(ALL) NOPASSWD:ALL    # this allows the user to execute any command as any user
                                                    (including as root user) without any password
                groups: users, admin    # this adds the user to other groups (users & admin group)
                lock_passwd: false      # this means the user account is not locked, so the user will not be
                                            required a password before they can login
                ssh_authorized_keys:
                    - ssh-rsa <key>
                    # the ssh_authorized_keys section allows you to Specify ssh-keys for the user, enabling
                        secure ssh access without using a password
                    # for the ssh-rsa <key>, replace the <key> with your rsa public key
        
        -
        3. Downloading and installing packages
        packages:
            - httpd
            - docker
        The above will download and install 2 packages, Apache httpd and Docker

        -
        4. Running commands on the system
        runcmd:
            - sudo systemctl start httpd
            - sudo systemctl start docker
            - sudo usermod -a -G docker ec2-user
            - sudo docker run -p 8080:80 nginx
        sudo: using sudo grants you all privileges so you can run & any commands you want
        systemctl: is a command used to control the systemd and system service manager
        "sudo usermod -a -G docker ec2-user":
            usermod: is used to modify the privileges and attributes of a user
            -a : user to append a user to a group without removing the user from another group
            -G : compliments -a, Specifies the group that the user should be added to
            {the "ec2-user" was added to the "docker" group, which allows the ec2-user to run any docker commands
             without needing to use sudo}
        "sudo docker run -p 8080:80 nginx":
            spins up a new docker container using an "nginx" image, the container will listen to request on port 8080,
            and map the request to nginx port 80

    - not_needed: use the cloud-init in your ec2
        data "template_file" "user_data" {
            # path to where the configuration is located relative to your main.tf
            template = file("./task/web-app-template-v1.yml")
        }

        resource "aws_instance" "my_vm" {
            ...
            # user_data = file("entry-script.sh") he commented this line out
            user_data = data.template_file.user_data.rendered
            ...
        }

37.
    - explain why this error occurred and how can it be solved
        so the main issue is that this is a new_project and all the terraform code here was copied from another
        terraform project_1, and in "project_1", the "aws_key_pair" has already been used
        (for every new ssh aws_key_pair you use, amazon creates it on your aws account using the key_name you used
        in creating the aws_key_pair), so now this new_project is trying to create a new aws_key_pair on aws using
        the same key_pair_name & the key already does exist, that's why an error occurred
        -
    - how you solve the above problem
        To solve this problem {the teacher says it is usually a common problem}, you have to import
        the aws_key_pair into this new_project, here is what you'll do:

        terraform import aws_key_pair.<local_name> <key_pair_name>
        -
        <local_name>: is the name you want to give to the resource in your Terraform configuration
        <key_pair_name>: is the actual name of the key pair in AWS.

        e.g:
        terraform import aws_key_pair.my_key_pair testing_ssh_key
        -
        resource "aws_key_pair" "my_key_pair" {
            key_name   = "testing_ssh_key"
            public_key = file("<path_to_file>")
        }
    - Read: read how you can find your key pairs on aws
        - Go to your aws console, go to the vpc section
        - Go to your Network & Security tab
        - Click on Key Pairs {it's a Link - here you'll see all d key pairs you've used in all ur different projects}

38.
    - login to your ec2 instance
        ssh -i ~/.ssh/test_rsa ec2-user@<PublicIP>

    - verify if all the users were created successfully
        tail /etc/passwd
        -
        you'll see stuffs like:
        terraform:x:1000:1000:terraform:/home/terraform:/bin/bash           # the user we created with cloud-init
        ec2-user:x:1001:1003:EC2 Default user :/home/ec2-user:/bin/bash     # default user created by aws_instance
        apache:x:48:48 ...                                                  # user created by apache

    - verify if all the groups were created successfully
        tail /etc/group
        -
        hashicorp:x:1000                # 1
        devops:x:1001:root              # 2
        admin:x:1002:terraform          # 3
        ec2-user:x:1003                 # 4
        apache:x:48                     # 5
        docker:x:992:ec2-user           # 6
        -
        1. Group name: hashicorp, Password: x, Group ID (GID): 1000, Members: No members
        2. Group name: devops, Password: x, Group ID (GID): 1001, Members: "root user"
        3. Group name: admin, Password: x, Group ID (GID): 1002, Members: "terraform user"
        4. Group name: ec2-user, Password: x, Group ID (GID): 1003, Members: No members
        5. Group name: apache, Password: x, Group ID (GID): 48, Members: No members
        6. Group name: docker, Password: x, Group ID (GID): 992, Members: "ec2-user user"

    - check if your httpd is running
        systemctl status httpd

    - check if your docker is running
        systemctl status docker

    - use your browser and confirm that the ec2 instance is accessible from the web
        http://35.159.20.29/
    - use your browser and confirm that the docker on your ec2 instance is running
        http://35.159.20.29:8080/

39. Read: read about how to troubleshot & logging in terraform
    ~ Always run "terraform fmt" and "terraform validate" before you run terraform "plan" or "apply".
    ~ To log your terraform operations in your production environment, you have to set your "TF_LOG"
        to either TRACE, DEBUG, INFO, WARN or ERROR 
    ~ Then to save all your logs to a file, you have to set TF_LOG_PATH to filename:
        e.g
            in your terminal do:
            export TF_LOG=DEBUG
            export TF_LOG_PATH=terraform.log
    ~ there are also other options such as TF_LOG_CORE & TF_LOG_PROVIDER, you can research them at your
        own convenience

================
SECTION 2 BEGINS
================
1. List the different value types in terraform
    - List simple types
        number, string, bool, null
    - List collection types
        list, map, set
    - List structural types
        tuple, object

2. Collection types
    - Give an example of using "list"
        variable "av_zones" {
            description = "availability_zones in the region"
            type = list(string)
            default = ["eu-central-1a", "eu-central-1b", "eu-central-1c"]
        }
        ---
        in main.tf
        resource "aws_subnet" "web_subnet" {
            availability_zone = var.av_zones[1] # eu-central-1b
        }

    - Give an example of using "maps"
        variable "amis" {
            description = "..."
            type = map(string)
            default = {
                "eu-central-1a" = "ami-something-eu-central"
                "us-west-1" = "ami-something-us-west-1"
            }
        }
        ---
        in main.tf
        resource "aws_instance" "my_vm" {
            ami = var.amis[var.region]
            or
            ami = var.amis["${var.region}"]
        }
    
3. Structural types
    - Give an example of using "tuple"
        variable "my_vm" {
            description = "..."
            type = tuple([string, number, bool])
            default = ["t2.micro", 1, true]
        }
        ---
        in main.tf
        resource "aws_subnet" "my_vm" {
            ami = var.amis[var.region]
            instance_type = var.my_vm[0]
            count = var.my_vm[1]
            associate_public_ip_address = var.my_vm[2]
        }

    - Give an example of using "object"
        variable "egress_dsg" {
            type = object({
                from_port = number
                to_port = number
                protocol = string
                cidr_blocks = list(string)
            })
            default = {
                from_port = 0,
                to_port = 65365, # maximum amount of ports
                protocol = "tcp",
                cidr_blocks = ["100.0.0.0/16", "200.0.0.0/16"]
            }
        }
        ---
        in main.tf
        resource "aws_security_group" "ec2_security" {
            ...
            egress {
                from_port = var.egress_dsg["from_port"]
                to_port = var.egress_dsg["to_port"]
                protocol = var.egress_dsg["protocol"]
                cidr_blocks = var.egress_dsg["cidr_blocks"]
            }
        }

4. The count meta-argument
    - What is count in terraform and what can it be used for
        - count is used to manage similar resources, you can use it to automatically scale up/down resources
        - count and for_each are looping techniques

    - Use count to create 3 aws instances
        resource "aws_instance" "my_vm" {
            ami = ....
            instance_type = "t3.micro"
            count = 3
        }

    - Using count & variable: "users" (list(string), a list of usernames), create 4 IAM users
        variable "users" {
            type = list(string)
            default = ["demo-user", "stanley", "edward", "chukwu"]
        }

        resource "aws_iam_user" "level2user" {
            name = "${element(var.users, count.index)}"
            path = "/system/"
            count = "${length(var.users)}"
        }
        {You can go to the terraform doc to see how you can customize the IAM users and set level/roles and what
          the users can have access to}

    - explain the element and length functions
        ~ element is used to retrieve an item from a list
        ~ length returns the total number of items in a list

    - when you do count=0 in any resource, what will happen when you run terraform apply
        when you set count = 0 in a resource block, that resource will not be created, if the resource already
        exists, the resource will be destroyed

5.  - Read: the for_each meta-argument {No need to master}
        for_each was introduced to overcome the downside of count, it works with either sets or maps
        e.g:
        variable "users" {
            type = list(string)
            default = ["demo-user", "stanley", "edward", "chukwu"]
        }
        -
        resource "aws_iam_user" "test" {
            for_each = toset(var.users) # toset converts the list(string) into a set
            name = each.key # each.key iterates over the set and grabs the key
        }

6.  
    - Read: take a look at looping with dynamic block
        dynamic block is another way of looping that can save us time
        e.g:
        variable "ingress_ports" {
            description = "List of Ingress Ports"
            type = list(number)
            default = [22, 80, 25, 443, 993, 8080]
        }
        -
        in main.tf
        resource "aws_security_group" "ec2_security" {
            vpc_id = aws_vpc.main.id

            dynamic "ingress" {
                for_each = var.ingress_ports
                content {
                    from_port = ingress.value
                    to_port = ingress.value
                    protocol = "tcp"
                    cidr_blocks = ["0.0.0.0/0"]
                }
            }

            egress {
                from_port = 0
                to_port = 0
                protocol = "-1"
                cidr_blocks = ["0.0.0.0/0"]
            }
        }

    - Read: what happens when you run terraform apply
        if you run terraform apply, your security group will be created with all the ports provided, you can
        go to your aws console to confirm this:
        ~ go to aws > search for "VPC" > SECURITY > SECURITY_GROUPS
        ~ select the security group you created, click on inbound rules
            here you'll see all the rules you've created with the dynamic block

    - Read: changing the iterator name
        you can set an iterator name to use in accessing the for_each values
        dynamic "ingress" {
            for_each = var.ingress_ports
            iterator = iport
            content {
                from_port = iport.value
                to_port = iport.value
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
            }
        }

    - Read: see the explanation for the different ports used
        1. Port 22:  
            - Service: SSH (Secure Shell)
            - Purpose: Used for secure remote login and command execution on a server.

        2. Port 80:  
            - Service: HTTP (Hypertext Transfer Protocol)
            - Purpose: Used for unencrypted web traffic, typically for websites that don't require security.

        3. Port 25:  
            - Service: SMTP (Simple Mail Transfer Protocol)
            - Purpose: For sending email btw mail servers. It’s often blocked by ISPs for outgoing mail to prevent spam.

        4. Port 443:  
            - Service: HTTPS (Hypertext Transfer Protocol Secure)
            - Purpose: For secure web traffic, which encrypts the communication btw a web server & a client (browser).

        5. Port 993:  
            - Service: IMAPS (Internet Message Access Protocol Secure)
            - Purpose: Used for secure access to email inboxes. It is an encrypted version of IMAP,
                       typically for retrieving email from a mail server.

        6. Port 8080:  
            - Service: HTTP Alternate (often used for proxies or web applications)
            - Purpose: A common port for web servers, often used as an alternative to port 80.
                       It may be used for proxy servers or other applications that require HTTP access.

7. Conditional Expressions
 - let's say we want to spin up different instances depending on our current environment, use
    terraform conditions and variables to check if we should launch an ec2_instance for testing
    or for production
    -
    variable "is_test" {
        description = "..."
        type = bool
    }
    -
    in terraform.tfvars
    is_test = true
    -
    in main.tf
    resource "aws_instance" "test_server" {
        ami = "..."
        instance_type = "t3.micro"
        count = var.is_test == true ? 1 : 0
    }
    resource "aws_instance" "production_server" {
        ami = "..."
        instance_type = "t3.large"
        count = var.is_test == false ? 1 : 0
    }

    You can also do stuffs like:
    instance_type = var.env_stage == "dev" ? "t3.micro" : "t3.large"

8. Locals
    - in what files can you save your locals
        You can define your locals in a file called locals.tf, you can also store them in variables.tf and
        lastly in main.tf(i.e if you do not have too many locals)

    - give an example of using locals
        in locals.tf
        locals {
            owner = "DevOps Corp Team"
            project = "online store"
            cidr_blocks = ["172.16.10.0/24", "172.16.20.0/24", "172.16.30.0/24"]
            common-tags = {
                Name = "Dev"
                Environment = "development"
                version = 1.10
            }
        }
        -
        in main.tf
        resource "aws_vpc" "dev_vpc" {
            cidr_block = "10.0.0.0/16"
            tags = local.common-tags
        }
        resource "aws_subnet" "dev_subnet" {
            vpc_id = aws_vpc.dev_vpc.id
            cidr_block = local.cidr_block[0]
            availability_zone = "eu-central-1a"
        }
        resource "aws_internet_gateway" "dev_igw" {
            vpc_id = aws_vpc.dev_vpc.id
            tags = {
                Name = local.common-tags["Name"]
                version = local.common-tags["Version"]
            }
        }

9. Terraform built-in functions
    If you go to the terraform documentation, navigate to the functions section, you'll see all of the
    functions provided by terraform. You cannot create your own custom functions in terraform

    - lookup function
        it retrieves a "value" from a "map" using a "key" from the map
        lookup(<map>, <key_name>)
        e.g ami = lookup(var.ami, var.region)

    - difference btw lookup & element function
        lookup retrieves an item from a map using the key of the value
        element retrieves an item from a list using the index of the value

    - file function
        The file function reads the content of a file and returns it as a string
        e.g user_data = file("entry-script.sh")

    - formatDate & timestamp()
        timestamp() is used to retrieve the current time
        formatDate() is used in to format the date received from timestamp()
        e.g:
        in locals.tf
          locals {
            time = formatDate("DD MM YYYY hh:mm", timestamp())
          }
        in outputs.tf
          output "CurrentTime" {
            description = "Current Date and Time"
            value = local.time
          }

10. Give an example of using splat expressions
    Lets say for example we have
    resource "aws_instance" "my_vm" {
        ami = "ami..."
        instance_type = "t3.micro"
        count = 3
        associate_public_ip_address = true
    }

    The above will create 3 ec2 instances, so how do we dynamically display the info of these aws_instance's.
    Say we wanted to display the ip addresses, we might do:
    output "ip_address_1" {
        value = aws_instance.my_vm[0].public_ip
    } 

    imagine if we created upTo 10vm, this would take forever, so we can use splat-expressions to dynamically
    loop through the vm's details, i.e:
    output "ip_addresses" {
        value = aws_instance.my_vm[*].public_ip
    }

11. Read: Terraform remote state
    - working with amazon s3 to store your state file
      you can use terraform to create your s3 bucket or you can go to the aws website and create your bucket there
      after creating the s3_bucket and dynamodb for state locking, add the below to your terraform "main.tf" or
      add it to another file called "backend.tf":

      terraform {
        required_providers { ... }

        backend "s3" {
          bucket = <name-of-bucket>
          key = <name-of-file> e.g s3_backend.tfstate # the file will be saved with this name in your bucket
          region = "eu-north-1"
          encrypt = true
          dynamodb_table = <name-of-table>
        }
      }

    - using dynamodb to implement state locking
      You can go to aws and create a dynamodb table from there, or you can use terraform to create a
      dynamodb_table, The dynamodb_table will help with state locking to prevent simultaneous updating
      of a state file

    - Read: working with terraform cloud to store your state file
        if you want to use terraform cloud for you .tfstate file storage, then here you go:
        -
        backend "remote" {
          organization = "glitch-stream"
          workspaces {
            name = "ci-cd-staging"
          }
        }

11.1
    - list all the resources
        D:\Sz - projects\28-devops\1-terraform\02-terraform-web-app-from-devops-directive\tree.txt
    - write the code for all the resources listed
        D:\Sz - projects\28-devops\1-terraform\02-terraform-web-app-from-devops-directive\main.tf

12. Modules
    - what is a module in terraform
        A module is a set of terraform configuration files in a single directory.
        Modules are a key to writing reuseable, maintainable, testable terraform code
    - what is a root module & child module
        - root module: A root module is the place where you run terraform plan or apply
        - child module: All modules imported from other directories into the root module are known as
            child module
    - what is the difference btw a local module and a remote module
        - Local modules: It is a module created by you or your team members and are loaded locally
        - Remote modules: There are modules that are loaded from remote sources such as terraform registry
            and are created and maintained by either hashicorp and it's partners or by 3rd parties

13. How do you structure your project to use modules
        root
        |__ project/
        |    |__ main.tf
        |
        |__ modules/
            |__ vpc/
            |    |__ main.tf
            |    |__ outputs.tf
            |    |__ variables.tf
            |
            |__ ec2/
            |    |__ main.tf
            |    |__ outputs.tf
            |    |__ variables.tf
            |
            |__ networking/
                |__ main.tf
                |__ outputs.tf
                |__ variables.tf

14. 
    - 4.1, 4.2, 4.3, 4.4
      All answers in: ./answers/14-modules-ec2/
    
    - what do you do after including a new module to your root module
      Anytime you import a new child module into a root module, you have to re-initialize your project:
      : "terraform init"

15. what makes a good module
    - Group resources in a logical fashion
    - Exposes input variable to allow necessary customization + composition
    - Provides useful defaults
    - Return outputs to make further integrations possible

16. As you separate into modules, what resources goes into which modules?
    - vpc module
        aws_vpc, aws_subnet, aws_internet_gateway, aws_route_table, aws_route_association_table
    - ec2 module
        aws_security_group, aws_key_pair, data.aws_ami, aws_instance
    - storage module
        aws_s3_bucket, aws_s3_bucket_server_side_encryption_configuration
    - network module
        aws_lb_listener, aws_lb_target_group, aws_lb_target_group_attachment, aws_lb_listener_rule,
        aws_security_group.alb_sg, aws_lb
    - dns module
        aws_route53_zone, aws_route53_record
    - database module
        aws_db_instance

17. Accessing child modules output
    - expose your vpc_id using an output from your vpc module and access it from the root module
        in ./modules/vpc/outputs.tf
            output "vpc_id" {
                value = aws_vpc.main.id
            }
        in ./projects/main.tf
            module "vpc_module" {
                source = "../module/vpc"
                ...
            }
        in ./projects/outputs.tf
            output "vpc_id" {
                description = "..."
                value = module.vpc_module.vpc_id
            }

    - what is the syntax for accessing the output of a child module
        module.<module_name>.<output_name>
    
    - how will different child modules access their outputs e.g:
      use the vpc_id from the "vpc_module" in the "ec2_module" to create the aws_security_group
        in ./modules/ec2/main.tf
            resource "aws_security_group" "ec2" {
                vpc_id = var.vpc_id
                ...
            }
        -
        in ./modules/ec2/variables.tf
            variable "vpc_id" {

            }
        -
        in ./projects/main.tf
            module "ec2_module" {
                source = "../modules/ec2"
                vpc_id = module.vpc_module.vpc_id
            }

    - how do you expose an entire resource as an output, e.g:
      - expose the entire ec2 instance in the ec2 module
        in ./modules/ec2/outputs.tf
            output "ec2_outputs" {
                value = aws_instance.my_vm
            }

      - access the values from the root module, get: ec2_ami, ec2_public_ip_address, ec2_instance_id
        in ./projects/outputs.tf
            output "ec2_ami" {
                value = module.ec2_module.ec2_outputs.ami
            }
            output "ec2_public_ip_address" {
                value = module.ec2_module.ec2_outputs.public_ip
            }
            output "ec2_instance_id" {
                value = module.ec2_module.ec2_outputs.id
            }

17.1 see what the final module of DevOps Directive looked like
    in projects/main.tf
    terraform { ... }
    provider "aws" { ... }
    -
    locals {
        env = terraform.workspace
    }
    -
    module "web_app" {
        source = "../../modules/web-app-module/"
        # input variables
        bucket_name = "devops-data-${local.env}"
        domain = "stanleychukwu.com"
        env = local.env
        instance_type = "t3.micro"
        create_dns_zone = terraform.workspace == "production" ? true : false
        db_name = "${local.env}-DB"
        db_user = "foo"
        db_pass = var.db_pass
    }

18. - Convert all the code/project from DevOps Directive to use modules

19. Terraform registry
    - Read: what is terraform registry
        Terraform registry is like npm, where you can find different modules and providers to use in your
        terraform project

    - Read: How to create a vpc using a module from terraform registry
        - he went to the terraform registry website @registry.terraform.io/modules/ and he searched for "vpc"
          and then selected "terraform-aws-modules/vpc"
        - under the readme section of the module, he copied the example there and pasted it on his main.tf,
          then he parameterized the values, the final result look something like:
            module "vpc" {
                source = "terraform-aws-modules/vpc/aws"
                name = "my-vpc"
                cidr_block = "10.0.0.0/16"
                ...
            }
          
          this module created a vpc, subnets, internet gateway & a route table

    - Read: How to create a security group using a module from terraform registry
        - search for "security group", then select "terraform-aws-modules/security-group"
        - he copied one of the examples and the final result looked like:
          module "sh_server_sg" {
            source = "terraform-aws-modules/security-group/aws/modules/ssh"
            name = "ssh"
            description = "security group for ssh ports open within the vpc"
            vpc_id = module.vpc.vpc_id

            ingress_cidr_blocks = ["0.0.0.0/0"]
          }

    - Read: How to create an ec2 instance using a module from terraform registry
        - Go and search for "ec2", select any of the module from the drop down, go through it's guide
          on setting up an ec2, and there you go!

    - Read: Accessing outputs from the modules
        - Go through each of the doc of the modules you're using to see how it exposes output, e.g for the
          vpc module we used earlier on, the the vpc_id would look like:
          -
          module.vpc.vpc_id

    - Read: ssh-ing into the aws_instance created using this module from terraform registry
        you cannot use the ec2-user as usual to ssh into the ec2 instance created from a module,
        the ec2-user is only available when you use the amazon-linux-images, if you're using a module to
        create an ec2 instance, then check the docs to know the right user to use for ssh-ing into
        the instance



================
SECTION 3 BEGINS
================
1. Drawing of images
    - Look at the image of the ec2 from lecture 1 and draw it on your own
        - see ./answers/1-draw-images/img1.jpg

    - Look at the image from DevOps Directive lecture and draw it on your own
        - see ./answers/1-draw-images/img2.jpg

2. How do you create an s3_bucket and dynamodb_table for storing and locking of .tfstate files
    - for s3_bucket
      resource "aws_s3_bucket" "bucket {
        bucket          = <unique_name_of_bucket>
        force_destroy   = true
      }

      resource "aws_s3_bucket_server_side_encryption_configuration" "encrypt" {
        bucket = aws_s3_bucket.bucket.bucket

        rule {
            apply_server_side_encryption_by_default {
                sse_algorithm = "AES256"
            }
        }
      }
    
    - for dynamodb
      resource "aws_dynamodb" "state_locking" {
        name            = "terraform-tfstate-locking"
        billing_mode    = "PAY_PER_REQUEST"
        hash_key        = "LOCKID"

        attribute {
            name = "LOCKID"
            type = "S"
        }
      }

3. Meta arguments in terraform
    - depends_on
        when you use depends_on, terraform automatically generates dependency graph based on reference.
        this will makes sure that resources that are depended on are created first before the ones that
        depends on it
        e.g:
        resource "aws_iam_role" "example" {
            name = "example"
            assume_role_policy = "..."
        }

        resource "aws_iam_instance_profile" "example" {
            role = aws_iam_role.example.name
        }

        resource "aws_iam_role_policy" "example" {
            name = "example"
            role = aws_iam_role.example.name
            policy = jsonencode({
                "statement" = [{
                    "Action" = "s3:*"
                    "Effort" = "Allow"
                }]
            })
        }

        resource "aws_instance" "example" {
            ami = "ami..."
            instance_type = "t3.micro"
            iam_instance_profile = aws_iam_instance_profile.example

            depends_on = [
                aws_iam_role_policy.example
            ]
        }

    - lifecycle:
        arguments you can use in lifecycle are: "create_before_destroy", "ignore_changes", "prevent_destroy"
        -
        create_before_destroy: can help with zero downtime, where a new resource is created before the current
                                one is destroyed
        ignore_changes: prevents terraform from trying to revert meta-data being set elsewhere
        prevent_destroy: causes terraform to reject any plan which would destroy the resource
        -
        e.g:
        resource "aws_instance" "my_vm" {
            ...
            instance_type = "t3.micro"

            lifecycle {
                create_before_destroy = true
                ignore_changes = [
                    tags
                ]
            }
        }

4. Managing multiple environment

    One-config: --------------------------------------------------------------
                |                           |                           |
            development                   staging                   production

    - workspaces:
        this involves you using multiple named sections within a single backend
        e.g staging, development, production e.t.c

    - File structure: talk about it (add note on referenced images p49)
        this involves using of directory layout, where you can use the same module in different sub-directories.
        variables in the different directories will determine what resources are created

        e.g:
        |__ modules
            |
            |__ vpc_module
            |
            |__ ec2_module
        |
        |__ development
            |__ main.tf, variables.tf, terraform.tfvars
        |
        |__ production
            |__ main.tf, variables.tf, terraform.tfvars
        |
        |__ staging
            |__ main.tf, variables.tf, terraform.tfvars

        some of the advantages of using file structure is, you can reference resources from different
        configurations(i.e entirely separate configurations), this is made possible by calling the different
        "config remote state file"
        e.g: say you deployed some ec2 instances in project-A and you need the i.p addresses of the ec2_instance
        in project-B, you can reference the "remote state file" of project-A from project-B to get the
        i.p address

5.  Read: How to use terraform workspace to manage environment 
    - creating a workspace
        terraform workspace new <name-of-workspace>
        e.g: terraform workspace new development
             terraform workspace new production

    - see all workspace
        terraform workspace list

    - switching btw workspaces
        terraform workspace switch <name-of-workspace>
        e.g: terraform workspace switch production

    - deleting of workspaces
        terraform workspace delete <name-of-workspace>
        e.g: terraform workspace delete development

6.  
    Read: Terragrunt
        This is a tool provided by grunt-work.io, it provide utilities to make certain terraform use cases easier.
        - keeping terraform code DRY
        - executing commands across multiple TF configs
        - working with multiple cloud accounts
        -
        it's a very great tool, once you start scaling up, you can research more on how to use this tool

    Read: using the "tree" command
        this one is just a terminal tip: you can use the "tree" command to see all your directories and
        sub-directories
        tree -a; # to see both hidden directories
        tree -L2; # to limit the sub-directories level show to 2
        -
        this command will only work in a pure linux environment, it works in my ubuntu-20.24(WSL), it won't work
        in my "git bash", but it works in macBook since they ship with linux

    Read: using Directory/File structure to manage environment
        you can have something like:
        -
        infra/
            modules/
                vpc_module/
                ec2_module/
            global/
                main.tf
            production/
                main.tf
            staging/
                main.tf

        the "global/main.tf" housed only resources that were shared by both production & staging.
        in  global/main.tf, you have:
        -
        terraform { ... }
        provider "aws" { ... }
        resource "aws_route53_zone" "primary" {
            name = "stanleychukwu.com"
        }




